{
  "name": "Snowflake_ML_Churn_Prediction_Workflow",
  "uuid": "98325f29-d4f7-48fb-92c7-8823d9f10635",
  "category": "Prediction - Classification",
  "description": "Churn Prediction using Decision Tree",
  "parameters": "",
  "nodes": [
    {
      "id": "2",
      "name": "StringIndexer",
      "description": "StringIndexer encodes a string column of labels to a column of label indices",
      "details": "<h2> String Indexer Node Details</h2>\n<br>\nThe String Indexer node encodes a string column of labels to a column of label indices. The indices are in [0, numLabels).<br>\n<br>\nBy default, this is ordered by label frequencies so the most frequent label gets index 0. The ordering behavior is controlled by setting <b>STRING ORDER TYPE</b>. Its default value is ‘frequencyDesc’. In case of equal frequency when under frequencyDesc/Asc, the strings are further sorted alphabetically<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> HANDLE INVALID : Specifies how to handle invalid data (unseen or NULL values) in features and label column of string type. Options are 'skip' (filter out rows with invalid data), or error (throw an error).</li>\n<li> VARIABLES : Allows multiple string columns to be selected for conversion.</li>\n<li> Input Columns : Select the column which needs to be converted.</li>\n<li> Output Columns : The name of the output converted column.</li>\n<li> STRING ORDER TYPE : Specifies how to order labels of string column. (default = \"frequencyDesc\")</li>\n</ul>\n    \"frequencyDesc\": descending order by label frequency (most frequent label assigned 0)<br>\n    \"frequencyAsc\": ascending order by label frequency (least frequent label assigned 0)<br>\n    \"alphabetDesc\": descending alphabetical order<br>\n    \"alphabetAsc\": ascending alphabetical order<br>",
      "examples": "<h2> String Indexer Node Example</h2>\n<br>\nAssume that we have the following DataFrame with columns id and category:<br>\n<br>\n id | category<br>\n----|----------<br>\n 0  | a<br>\n 1  | b<br>\n 2  | c<br>\n 3  | a<br>\n 4  | a<br>\n 5  | c<br>\ncategory is a string column with three labels: \"a\", \"b\", and \"c\". Applying <b>StringIndexer</b> with <b>category</b> as the input column and <b>categoryIndex</b> as the output column, we should get the following:<br>\n<br>\n id | category | categoryIndex<br>\n----|----------|---------------<br>\n 0  | a        | 0.0<br>\n 1  | b        | 2.0<br>\n 2  | c        | 1.0<br>\n 3  | a        | 0.0<br>\n 4  | a        | 0.0<br>\n 5  | c        | 1.0<br>\n\"a\" gets index 0 because it is the most frequent, followed by \"c\" with index 1 and \"b\" with index 2.<br>",
      "type": "ml-transformer",
      "nodeClass": "fire.nodes.ml.NodeStringIndexer",
      "x": "313.1409912109375px",
      "y": "272.7969970703125px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "handleInvalid",
          "value": "error",
          "widget": "array",
          "title": "Handle Invalid",
          "description": "Invalid entries to be skipped or thrown error",
          "optionsArray": [
            "skip",
            "error"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "inputCols",
          "value": "[\"intl_plan\",\"churned\"]",
          "widget": "variables_list_select",
          "title": "Input Columns",
          "description": "Input columns for encoding",
          "datatypes": [
            "string"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "outputCols",
          "value": "[\"intl_plan_index\",\"label\"]",
          "widget": "variables_list_textfield",
          "title": "Output Columns",
          "description": "Output columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "stringOrderType",
          "value": "frequencyDesc",
          "widget": "array",
          "title": "String Order Type",
          "description": "Param for how to order labels of string column",
          "optionsArray": [
            "frequencyDesc",
            "frequencyAsc",
            "alphabetDesc",
            "alphabetAsc"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "6",
      "name": "Predict",
      "description": "Predict node takes in a DataFrame and Model and makes predictions",
      "details": "Predict node takes in a DataFrame and Model and makes predictions on the data using the Model.<br>",
      "examples": "",
      "type": "ml-predict",
      "nodeClass": "fire.nodes.ml.NodePredict",
      "x": "830.7030029296875px",
      "y": "282.343994140625px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "7",
      "name": "PrintNRows",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "1010.1875px",
      "y": "255.4375px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "title",
          "value": "Row Values",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "all"
    },
    {
      "id": "9",
      "name": "VectorAssembler",
      "description": "Merges multiple columns into a vector column",
      "details": "",
      "examples": "<h2> h2: VectorAssembler Node Example</h2>\n<br>\nAssume that we have a DataFrame with the columns id, hour, mobile, userFeatures, and clicked:<br>\n<br>\n id | hour | mobile | userFeatures     | clicked<br>\n----|------|--------|------------------|---------<br>\n 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0<br>\n<br>\n If we set VectorAssembler's <b>input Selected columns</b> to hour, mobile, and userFeatures and <b>output column</b> to features, after transformation we should get the following DataFrame:<br>\n<br>\n id | hour | mobile | userFeatures     | clicked | features<br>\n----|------|--------|------------------|---------|-----------------------------<br>\n 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0     | [18.0, 1.0, 0.0, 10.0, 0.5]<br>",
      "type": "ml-transformer",
      "nodeClass": "fire.nodes.ml.NodeVectorAssembler",
      "x": "475.906005859375px",
      "y": "274.906005859375px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "inputCols",
          "value": "[\"number_vmail_messages\",\"today_day_minutes\",\"today_day_calls\",\"total_eve_minutes\",\"total_eve_call\",\"total_night_minutes\",\"total_night_calls\",\"total_intl_minutes\",\"total_intl_calls\",\"number_customer_service_calls\",\"intl_plan_index\"]",
          "widget": "variables",
          "title": "Input Columns",
          "description": "Input column of type - all numeric, boolean and vector",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float",
            "vectorudt"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "outputCol",
          "value": "feature_v",
          "widget": "textfield",
          "title": "Output Column",
          "description": "Output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "handleInvalid",
          "value": "error",
          "widget": "array",
          "title": "HandleInvalid",
          "description": "How to handle invalid data (NULL values). Options are 'skip' (filter out rows with invalid data), 'error' (throw an error), or 'keep' (return relevant number of NaN in the output).",
          "optionsArray": [
            "error",
            "skip",
            "keep"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "10",
      "name": "RandomForestClassifier",
      "description": "Supports both binary and multiclass labels, as well as both continuous and categorical features.",
      "details": "Random forests are a popular family of classification and regression methods.<br>\nRandom forests supports both binary and multiclass labels, as well as both continuous and categorical features.<br>\n<br>\nRandom forests are ensembles of decision trees. Random forests combine many decision trees in order to reduce the risk of overfitting. The spark.ml implementation supports random forests for binary and multiclass classification and for regression, using both continuous and categorical features.<br>\n<br>\nMore details are available at Apache Spark ML docs page:<br>\n<br>\n<a href=\"http://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\" target=\"_blank\">spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier</a><br>",
      "examples": "Below example is available at : <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\" target=\"_blank\">spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier</a><br>\n<br>\nimport org.apache.spark.ml.Pipeline<br>\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}<br>\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator<br>\nimport org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}<br>\n<br>\n// Load and parse the data file, converting it to a DataFrame.<br>\nval data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")<br>\n<br>\n// Index labels, adding metadata to the label column.<br>\n// Fit on whole dataset to include all labels in index.<br>\nval labelIndexer = new StringIndexer()<br>\n  .setInputCol(\"label\")<br>\n  .setOutputCol(\"indexedLabel\")<br>\n  .fit(data)<br>\n// Automatically identify categorical features, and index them.<br>\n// Set maxCategories so features with > 4 distinct values are treated as continuous.<br>\nval featureIndexer = new VectorIndexer()<br>\n  .setInputCol(\"features\")<br>\n  .setOutputCol(\"indexedFeatures\")<br>\n  .setMaxCategories(4)<br>\n  .fit(data)<br>\n<br>\n// Split the data into training and test sets (30% held out for testing).<br>\nval Array(trainingData, testData) = data.randomSplit(Array(0.7, 0.3))<br>\n<br>\n// Train a RandomForest model.<br>\nval rf = new RandomForestClassifier()<br>\n  .setLabelCol(\"indexedLabel\")<br>\n  .setFeaturesCol(\"indexedFeatures\")<br>\n  .setNumTrees(10)<br>\n<br>\n// Convert indexed labels back to original labels.<br>\nval labelConverter = new IndexToString()<br>\n  .setInputCol(\"prediction\")<br>\n  .setOutputCol(\"predictedLabel\")<br>\n  .setLabels(labelIndexer.labelsArray(0))<br>\n<br>\n// Chain indexers and forest in a Pipeline.<br>\nval pipeline = new Pipeline()<br>\n  .setStages(Array(labelIndexer, featureIndexer, rf, labelConverter))<br>\n<br>\n// Train model. This also runs the indexers.<br>\nval model = pipeline.fit(trainingData)<br>\n<br>\n// Make predictions.<br>\nval predictions = model.transform(testData)<br>\n<br>\n// Select example rows to display.<br>\npredictions.select(\"predictedLabel\", \"label\", \"features\").show(5)<br>\n<br>\n// Select (prediction, true label) and compute test error.<br>\nval evaluator = new MulticlassClassificationEvaluator()<br>\n  .setLabelCol(\"indexedLabel\")<br>\n  .setPredictionCol(\"prediction\")<br>\n  .setMetricName(\"accuracy\")<br>\nval accuracy = evaluator.evaluate(predictions)<br>\nprintln(s\"Test Error = ${(1.0 - accuracy)}\")<br>\n<br>\nval rfModel = model.stages(2).asInstanceOf[RandomForestClassificationModel]<br>\nprintln(s\"Learned classification forest model:\\n ${rfModel.toDebugString}\")<br>",
      "type": "ml-estimator",
      "nodeClass": "fire.nodes.ml.NodeRandomForestClassifier",
      "x": "819.89599609375px",
      "y": "126.88500213623047px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "featuresCol",
          "value": "feature_v",
          "widget": "variable",
          "title": "Features Column",
          "description": "Features column of type vectorUDT for model fitting",
          "datatypes": [
            "vectorudt"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "labelCol",
          "value": "label",
          "widget": "variable",
          "title": "Label Column",
          "description": "The label column for model fitting",
          "datatypes": [
            "double"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "predictionCol",
          "value": "",
          "widget": "textfield",
          "title": "Prediction Column",
          "description": "The prediction column created during model scoring.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "featureSubsetStrategy",
          "value": "auto",
          "widget": "array",
          "title": "Feature Subset Strategy",
          "description": "The number of features to consider for splits at each tree node.",
          "optionsArray": [
            "auto",
            "onethird",
            "sqrt",
            "log2"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "impurity",
          "value": "gini",
          "widget": "array",
          "title": "Impurity",
          "description": "The Criterion used for information gain calculation",
          "optionsArray": [
            "gini",
            "entropy"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "maxBins",
          "value": "32",
          "widget": "textfield",
          "title": "Max Bins",
          "description": "The maximum number of bins used for discretizing continuous features.Must be >= 2 and >= number of categories in any categorical feature.",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "maxDepth",
          "value": "5",
          "widget": "textfield",
          "title": "Max Depth",
          "description": "The Maximum depth of a tree",
          "datatypes": [
            "int"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "minInfoGain",
          "value": "0.0",
          "widget": "textfield",
          "title": "Min Information Gain",
          "description": "The Minimum information gain for a split to be considered at a tree node",
          "datatypes": [
            "double"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "minInstancesPerNode",
          "value": "1",
          "widget": "textfield",
          "title": "Min Instances Per Node",
          "description": "The Minimum number of instances each child must have after split",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "numTrees",
          "value": "20",
          "widget": "textfield",
          "title": "Num Trees",
          "description": "The number of trees to train",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "subsamplingRate",
          "value": "1.0",
          "widget": "textfield",
          "title": "Subsampling Rate",
          "description": "The fraction of the training data used for learning each decision tree.",
          "datatypes": [
            "double"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "seed",
          "value": "",
          "widget": "textfield",
          "title": "Seed",
          "description": "The random seed",
          "datatypes": [
            "long"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "cacheNodeIds",
          "value": "false",
          "widget": "array",
          "title": "Cache Node Ids",
          "description": "The caching nodes IDs. Can speed up training of deeper trees.",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "checkpointInterval",
          "value": "10",
          "widget": "textfield",
          "title": "Checkpoint Interval",
          "description": "The checkpoint interval. E.g. 10 means that the cache will get checkpointed every 10 iterations.Set checkpoint interval (>= 1) or disable checkpoint (-1)",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "maxMemoryInMB",
          "value": "256",
          "widget": "textfield",
          "title": "Max memory",
          "description": "Maximum memory in MB allocated to histogram aggregation.",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "minWeightFractionPerNode",
          "value": "1.0",
          "widget": "textfield",
          "title": "Min weight fraction per node",
          "description": "Minimum fraction of the weighted sample count that each child must have after split",
          "datatypes": [
            "double"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "bootstrap",
          "value": "true",
          "widget": "array",
          "title": "Bootstrap",
          "description": "Whether bootstrap samples are used when building trees.",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "weightCol",
          "value": "",
          "widget": "variable",
          "title": "Weight Column",
          "description": "Param for weight column name. If this is not set or empty, we treat all instance weights as 1.0.",
          "datatypes": [
            "double"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "gridSearch",
          "value": "",
          "widget": "tab",
          "title": "Grid Search",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "minInfoGainGrid",
          "value": "",
          "widget": "textfield",
          "title": "Min Information Gain Param Grid Search",
          "description": "Min Information Gain Parameters for Grid Search",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "maxBinsGrid",
          "value": "",
          "widget": "textfield",
          "title": "Max Bins Param Grid Search",
          "description": "Max Bins Parameters for Grid Search",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "maxDepthGrid",
          "value": "",
          "widget": "textfield",
          "title": "Max Depth Param Grid Search",
          "description": "Max Depth Parameters for Grid Search",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "numTreesGrid",
          "value": "",
          "widget": "textfield",
          "title": "Number trees Param Grid Search",
          "description": "Total number of trees Parameters for Grid Search",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "11",
      "name": "Split With Stratified Sampling",
      "description": "This node splits the incoming DataFrame into 2. It takes in the fraction to use in splitting the data by Stratified Sampling.",
      "details": "Split With Stratified Sampling, which is the preferred way to sample from populations with varing subpopulation sizes.<br>\n<br>\nReturns a stratified sample without replacement based on the fraction given on each stratum.<br>\n<br>\nMore details are available at : <a href=\"https://spark.apache.org/docs/latest/api/python/_modules/pyspark/sql/dataframe.html#DataFrame.sampleBy\" target=\"_blank\">spark.apache.org/docs/latest/api/python/_modules/pyspark/sql/dataframe.html#DataFrame.sampleBy</a><br>",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.util.SplitWithStratifiedSampling",
      "x": "640.8679809570312px",
      "y": "273.87799072265625px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "keyInputCol",
          "value": "label",
          "widget": "variable",
          "title": "Column Name",
          "description": "column that defines strata",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "fraction",
          "value": "0.8",
          "widget": "textfield",
          "title": "Fraction",
          "description": "sampling fraction for each stratum. If a stratum is not specified, we treat its fraction as zero",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "seed",
          "value": "0",
          "widget": "textfield",
          "title": "Seed",
          "description": "random seed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "12",
      "name": "StickyNote",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "13px",
      "y": "6.000000476837158px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "bgColor",
          "value": "blue",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "width",
          "value": "589px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "height",
          "value": "210px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "comment",
          "value": "<p>Churn Prediction:</p><p>Refer the <strong>Churn Data Analysis </strong>workflows for data exploration.</p><p><br></p><p><em style=\"color: rgb(0, 0, 0);\">Total day minutes</em><span style=\"color: rgb(0, 0, 0);\">&nbsp;and&nbsp;</span><em style=\"color: rgb(0, 0, 0);\">Total day charge</em><span style=\"color: rgb(0, 0, 0);\">&nbsp;are highly correlated fields. Such correlated data won't be very beneficial for our model training runs, so we're going to remove them. We'll do so by dropping one column of each pair of correlated fields, along with the&nbsp;</span><em style=\"color: rgb(0, 0, 0);\">State</em><span style=\"color: rgb(0, 0, 0);\">&nbsp;and&nbsp;</span><em style=\"color: rgb(0, 0, 0);\">Area</em><span style=\"color: rgb(0, 0, 0);\">&nbsp;code columns, which we also won’t use.</span></p><p><br></p><p>Use <span style=\"color: rgb(0, 0, 0);\">stratified sampling for split.</span></p><p><br></p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "13",
      "name": "BinaryClassificationEvaluator",
      "description": "Evaluator for binary classification, which expects two input columns: rawPrediction and label.",
      "details": "Evaluator for binary classification, which expects two input columns: rawPrediction and label.<br>\n<br>\n<br>\nMore at Spark MLlib/ML docs page : <a href=\"http://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification\" target=\"_blank\">spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification</a><br>",
      "examples": "<h2>Below example is available at : <a href=\"https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification\" target=\"_blank\">spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification</a></h2>\n<br>\nimport org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS<br>\nimport org.apache.spark.mllib.evaluation.BinaryClassificationMetrics<br>\nimport org.apache.spark.mllib.regression.LabeledPoint<br>\nimport org.apache.spark.mllib.util.MLUtils<br>\n<br>\n// Load training data in LIBSVM format<br>\nval data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_binary_classification_data.txt\")<br>\n<br>\n// Split data into training (60%) and test (40%)<br>\nval Array(training, test) = data.randomSplit(Array(0.6, 0.4), seed = 11L)<br>\ntraining.cache()<br>\n<br>\n// Run training algorithm to build the model<br>\nval model = new LogisticRegressionWithLBFGS()<br>\n  .setNumClasses(2)<br>\n  .run(training)<br>\n<br>\n// Clear the prediction threshold so the model will return probabilities<br>\nmodel.clearThreshold<br>\n<br>\n// Compute raw scores on the test set<br>\nval predictionAndLabels = test.map { case LabeledPoint(label, features) =><br>\n  val prediction = model.predict(features)<br>\n  (prediction, label)<br>\n}<br>\n<br>\n// Instantiate metrics object<br>\nval metrics = new BinaryClassificationMetrics(predictionAndLabels)<br>\n<br>\n// Precision by threshold<br>\nval precision = metrics.precisionByThreshold<br>\nprecision.collect.foreach { case (t, p) =><br>\n  println(s\"Threshold: $t, Precision: $p\")<br>\n}<br>\n<br>\n// Recall by threshold<br>\nval recall = metrics.recallByThreshold<br>\nrecall.collect.foreach { case (t, r) =><br>\n  println(s\"Threshold: $t, Recall: $r\")<br>\n}<br>\n<br>\n// Precision-Recall Curve<br>\nval PRC = metrics.pr<br>\n<br>\n// F-measure<br>\nval f1Score = metrics.fMeasureByThreshold<br>\nf1Score.collect.foreach { case (t, f) =><br>\n  println(s\"Threshold: $t, F-score: $f, Beta = 1\")<br>\n}<br>\n<br>\nval beta = 0.5<br>\nval fScore = metrics.fMeasureByThreshold(beta)<br>\nfScore.collect.foreach { case (t, f) =><br>\n  println(s\"Threshold: $t, F-score: $f, Beta = 0.5\")<br>\n}<br>\n<br>\n// AUPRC<br>\nval auPRC = metrics.areaUnderPR<br>\nprintln(s\"Area under precision-recall curve = $auPRC\")<br>\n<br>\n// Compute thresholds used in ROC and PR curves<br>\nval thresholds = precision.map(_._1)<br>\n<br>\n// ROC Curve<br>\nval roc = metrics.roc<br>\n<br>\n// AUROC<br>\nval auROC = metrics.areaUnderROC<br>\nprintln(s\"Area under ROC = $auROC\")<br>",
      "type": "ml-evaluator",
      "nodeClass": "fire.nodes.ml.NodeBinaryClassificationEvaluator",
      "x": "842.9649658203125px",
      "y": "455.9649963378906px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "labelCol",
          "value": "label",
          "widget": "variable",
          "title": "Label Column",
          "description": "The label column for model fitting.",
          "datatypes": [
            "double"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "predictionCol",
          "value": "prediction",
          "widget": "variable",
          "title": "Prediction Column",
          "description": "The prediction column.",
          "datatypes": [
            "double"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "14",
      "name": "StickyNote",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "574px",
      "y": "462px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "bgColor",
          "value": "yellow",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "width",
          "value": "253px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "height",
          "value": "73px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "comment",
          "value": "<p>Evaluate the results of the prediction</p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "15",
      "name": "StickyNote",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "897px",
      "y": "153px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "bgColor",
          "value": "yellow",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "width",
          "value": "244px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "height",
          "value": "73px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "comment",
          "value": "<p>Display the Predictions</p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "16",
      "name": "StickyNote",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "736px",
      "y": "31px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "bgColor",
          "value": "yellow",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "width",
          "value": "259px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "height",
          "value": "74px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "comment",
          "value": "<p>Create Random Forest Model for predicting Churn</p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "17",
      "name": "DropRowsWithNull",
      "description": "This node creates a new DataFrame by dropping rows containing null values",
      "details": "This node creates a new DataFrame by dropping rows containing NULL values in any of the columns.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE05       |    MARK        |               |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE03       |    TONY        |    MARKETING  |    <br>\nE04       |    MARTIN      |    MARKETING  |    45<br>\n<br>\nIncoming Dataframe has NULL values for two rows. <br>\nUsing DropRowsWithNull node would result in below outgoing Dataframe created by dropping rows having NULL values in any of the columns:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE04       |    MARTIN      |    MARKETING  |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropRowsWithNull",
      "x": "164px",
      "y": "271px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "18",
      "name": "Read From SnowFlake",
      "description": "This node reads a table from Snowflake",
      "details": "<h2> Read From SnowFlake Node Details</h2>\n<br>\nThis node reads a table from Snowflake and creates the Dataframe which contains the schema and data of the specified table.<br>\n<br>\n<h4> Parameters to be set:</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> CONNECTION : Select the desired snowflake connection to be used.</li>\n<li> SNOWFLAKE WAREHOUSE : Specify the virtual warehouse to use for the connection.</li>\n<li> SNOWFLAKE DATABASE : Specify the database to use once connected.</li>\n<li> SNOWFLAKE SCHEMA : Specify the schema to use for the specified database once connected.</li>\n<li> SNOWFLAKE TABLE : Specify the table from which data is to be read.</li>\n</ul>",
      "examples": "<h2> Read From SnowFlake Node Examples</h2>\n<br>\n<h4> Example of Connection Values</h4>\n<ul>\n<li> CONNECTION : SNOWFLAKE_DEV_ENV_NCUS</li>\n<li> SNOWFLAKE WAREHOUSE : SNOWFLAKE_BI_VWH</li>\n<li> SNOWFLAKE DATABASE : CUSTOMER_SALES_NCUS</li>\n<li> SNOWFLAKE SCHEMA : INT_NA_CUSTSALES</li>\n<li> SNOWFLAKE TABLE : CUST_BASIC</li>\n</ul>",
      "type": "dataset",
      "nodeClass": "fire.nodes.snowflake.NodeReadFromSnowFlake",
      "x": "27.65625px",
      "y": "414.65625px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "connection",
          "value": "7",
          "widget": "object_array",
          "title": "Connection",
          "description": "The Snowflake connection to connect",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "sfWarehouse",
          "value": "COMPUTE_WH",
          "widget": "textfield",
          "title": "Snowflake Warehouse",
          "description": "Warehouse for connecting to the SnowFlake",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "sfDatabase",
          "value": "MY_DB",
          "widget": "textfield",
          "title": "Snowflake Database",
          "description": "Database for connecting to the SnowFlake",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "sfSchema",
          "value": "MY_SC",
          "widget": "textfield",
          "title": "Snowflake Schema",
          "description": "Schema for connecting to the SnowFlake",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "dbtable",
          "value": "CHURN_PREDICTION",
          "widget": "textfield",
          "title": "Snowflake Table",
          "description": "Snowflake Table from which to read the data",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "outputColNames",
          "value": "[\"state\",\" account_length\",\" area_code\",\"phone_number\",\" intl_plan\",\" voice_mail_plan\",\" number_vmail_messages\",\" today_day_minutes\",\"today_day_calls\",\"today_day_change\",\"total_eve_minutes\",\"total_eve_call\",\"total_eve_charge\",\"total_night_minutes\",\"total_night_calls\",\"total_night_charge\",\"total_intl_minutes\",\"total_intl_calls\",\"total_intl_charge\",\"number_customer_service_calls\",\"churned\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "all"
    },
    {
      "id": "19",
      "name": "Columns Rename",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "details": "This node creates a new DataFrame by renaming existing columns with the new name.<br>\n<br>\nFor the columns to be renamed, provide the new column name. The output dataframe would have the specified columns renamed to the new ones.<br>",
      "examples": "If incoming Dataframe has a column as [CUST NAME] that needs to be renamed to [CUST_NAME] then below details need to be provided in the node:<br>\n<br>\n<ul>\n<li> CURRENT COLUMN NAMES : CUST NAME</li>\n<li> COLUMNS NEW NAME : CUST_NAME</li>\n</ul>\nThis would result in output Dataframe having renameed column [CUST_NAME]. A seprate row needs to be added for each Column Rename requirement.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "16.777799606323242px",
      "y": "243.7779998779297px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "currentColNames",
          "value": "[\"intl_plan\",\"churned\",\"account_length\",\"area_code\",\"phone_number\",\"voice_mail_plan\",\"number_vmail_messages\",\"today_day_minutes\",\"today_day_calls\",\"today_day_change\",\"total_eve_minutes\",\"total_eve_call\",\"total_eve_charge\",\"total_night_minutes\",\"total_night_calls\",\"total_night_charge\",\"total_intl_minutes\",\"total_intl_calls\",\"total_intl_charge\",\"number_customer_service_calls\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "newColNames",
          "value": "[\"intl_plan\",\"churned\",\" account_length\",\"area_code\",\"phone_number\",\"voice_mail_plan\",\"number_vmail_messages\",\"today_day_minutes\",\"today_day_calls\",\"today_day_change\",\"total_eve_minutes\",\"total_eve_call\",\"total_eve_charge\",\"total_night_minutes\",\"total_night_calls\",\"total_night_charge\",\"total_intl_minutes\",\"total_intl_calls\",\"total_intl_charge\",\"number_customer_service_calls\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "6",
      "target": "7",
      "id": 1
    },
    {
      "source": "2",
      "target": "9",
      "id": 2
    },
    {
      "source": "10",
      "target": "6",
      "id": 3
    },
    {
      "source": "9",
      "target": "11",
      "id": 4
    },
    {
      "source": "11",
      "target": "10",
      "id": 5
    },
    {
      "source": "11",
      "target": "6",
      "id": 6
    },
    {
      "source": "6",
      "target": "13",
      "id": 7
    },
    {
      "source": "17",
      "target": "2",
      "id": 8
    },
    {
      "source": "18",
      "target": "19",
      "id": 9
    },
    {
      "source": "19",
      "target": "17",
      "id": 10
    }
  ],
  "dataSetDetails": [],
  "engine": "scala"
}